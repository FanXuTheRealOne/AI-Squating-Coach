{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf76960-b3e4-4dbf-bb71-8afaa3eb7d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Env check--------\n",
      "/opt/anaconda3/envs/Testing/bin/python\n",
      "['Python 3.11.14']\n"
     ]
    }
   ],
   "source": [
    "print(\"--------Env check--------\")\n",
    "import sys\n",
    "from PIL import Image\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "print(sys.executable)\n",
    "pythonVersion = !python --version\n",
    "print(pythonVersion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1563621-330c-45e6-ae6d-6d83a3df0507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Importing Required Libraries--------\n"
     ]
    }
   ],
   "source": [
    "print(\"--------Importing Required Libraries--------\")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7fdb47a-4220-41b8-a996-555f6d834f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Working device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaec7e8-0558-4c77-a641-71054988c458",
   "metadata": {},
   "source": [
    "# 1. Model preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5131e281-6266-41dc-982a-7087e56322df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!huggingface-cli download apple/FastVLM-0.5B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47ba4685-9ecf-4879-a4b5-cec9f2beae36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Model Name: 'apple/FastVLM-0.5B' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Testing/lib/python3.11/site-packages/accelerate/utils/modeling.py:1598: UserWarning: The following device_map keys do not match any submodules in the model: ['model.vision_tower.vision_tower.model.network.10.1.layer_scale_1', 'model.vision_tower.vision_tower.model.network.10.1.layer_scale_2']\n",
      "  warnings.warn(\n",
      "Some parameters are on the meta device because they were offloaded to the disk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working device: cpu，float: torch.float32\n"
     ]
    }
   ],
   "source": [
    "MID = \"apple/FastVLM-0.5B\"\n",
    "IMAGE_TOKEN_INDEX = -200 \n",
    "\n",
    "print(f\"--- 1. Model Name: '{MID}' ---\")\n",
    "\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MID, trust_remote_code=True)\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MID,\n",
    "    torch_dtype=dtype,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "print(f\"working device: {device}，float: {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f1b9e0-4eff-4dbb-8911-b2d16c2f9cd2",
   "metadata": {},
   "source": [
    "# 2. Load image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0f1e689-e983-4495-a69a-e8a413ffefdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 'squatImage1.jpeg' loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "image_path = \"squatImage1.jpeg\"\n",
    "try:\n",
    "    # Use Pillow library to load the image and convert it to RGB format\n",
    "    img = Image.open(image_path).convert(\"RGB\") \n",
    "    print(f\"Image '{image_path}' loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found '{image_path}'. Please check the filename and path.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92609b1-85fc-4e35-bd89-4fc4045f2745",
   "metadata": {},
   "source": [
    "# 3. Define The prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9db69ad0-c186-4cbb-91a3-e6eaf7e61c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": f\"<image>\\n Describe the this photo and rate his suqatting posture。\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf944585-d45d-4e4d-9a3e-c6cd0993abfa",
   "metadata": {},
   "source": [
    "# 4. Prepare Model Input (FastVLM-specific Complex Steps)\n",
    "\n",
    "- Format the Conversation String\n",
    "- apply_chat_template converts the list of messages into a single string \n",
    "- that matches the model's training format, without tokenizing yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6dca440d-920f-4c4d-adbb-85a30cbdd394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Process Done Start inference...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rendered = tok.apply_chat_template(\n",
    "    messages, add_generation_prompt=True, tokenize=False\n",
    ")\n",
    "\n",
    "# B. Split the String and Prepare Token IDs\n",
    "pre, post = rendered.split(\"<image>\", 1) # Split the string at the <image> boundary\n",
    "pre_ids  = tok(pre,  return_tensors=\"pt\", add_special_tokens=False).input_ids\n",
    "post_ids = tok(post, return_tensors=\"pt\", add_special_tokens=False).input_ids\n",
    "\n",
    "# C. Concatenate the Token Sequence: [Prefix Text IDs] + [Image Placeholder] + [Suffix Text IDs]\n",
    "img_tok = torch.tensor([[IMAGE_TOKEN_INDEX]], dtype=pre_ids.dtype)\n",
    "input_ids = torch.cat([pre_ids, img_tok, post_ids], dim=1).to(model.device) # Move to the model's device\n",
    "\n",
    "# D. Create the Attention Mask\n",
    "attention_mask = torch.ones_like(input_ids, device=model.device)\n",
    "\n",
    "# E. Image Pre-processing\n",
    "# get_vision_tower().image_processor accesses the model's built-in image processor \n",
    "# to handle scaling and normalization.\n",
    "px = model.get_vision_tower().image_processor(images=img, return_tensors=\"pt\")[\"pixel_values\"]\n",
    "px = px.to(model.device, dtype=model.dtype) # Move to the model's device and match its data type\n",
    "\n",
    "print(\"Data Process Done: Start inference...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bb0f4cf1-e965-46c1-b391-c855c34ac710",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): # Disables gradient tracking to boost inference speed and save memory.\n",
    "    out = model.generate(\n",
    "        inputs=input_ids,       # The sequence of text token IDs.\n",
    "        attention_mask=attention_mask, # The attention mask, indicating valid tokens.\n",
    "        images=px,              # The pre-processed image pixel tensor.\n",
    "        max_new_tokens=128,     # Limits the maximum length of the generated text response.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "35ec071b-957c-4c7f-95b0-477db767fa84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "FastVLM Inference Result:\n",
      "The squatting posture shown in the image is one of active squatting. In this specific pose, both knees are bent, and the body is straight or slightly tilted to one side, with the weight of the body resting on the back hand and back leg. Since the person is squatting in a wide-legged manner, they are engaging both the hamstrings and quadriceps muscles to increase the resistance of the exercise. The knees appear to be raised, which helps to deepen the strength of these muscles. Maintaining a straight arm and shoulder angle ensures that the body effectively works through the exercise. It generally resembles the squat and is an essential muscle\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Decode & Print Result ---\n",
    "# Decoding it\n",
    "decoded_output = tok.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"FastVLM Inference Result:\")\n",
    "print(decoded_output)\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f216f9-b93c-4515-9e36-df3ae4554407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577f0584-a4ad-43f0-9f4c-cb729e3ecb0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Testing]",
   "language": "python",
   "name": "conda-env-Testing-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
